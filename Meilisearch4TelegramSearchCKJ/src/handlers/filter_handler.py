#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
filter_handler.py - Handles banning, filtering, and deletion logic
"""
import ast
from telethon import Button, TelegramClient
from telethon.tl.types import PeerUser
from Meilisearch4TelegramSearchCKJ.src.config.env import BANNED_WORDS # Import default if needed
from Meilisearch4TelegramSearchCKJ.src.models.meilisearch_handler import MeiliSearchClient
from Meilisearch4TelegramSearchCKJ.src.utils.record_lastest_msg_id import load_config, save_config
from Meilisearch4TelegramSearchCKJ.src.utils.permissions import set_permission

class FilterHandler:
    """Handles commands and interactions related to filtering and banning."""

    def __init__(self, bot_client: TelegramClient, meili: MeiliSearchClient, logger):
        self.bot_client = bot_client
        self.meili = meili
        self.logger = logger

    # --- Command Handlers ---

    @set_permission
    async def handle_ban_command(self, event) -> None:
        """Handles the /ban command."""
        tokens = event.text.split()[1:]
        if not tokens:
            await event.reply("ç”¨æ³•: /ban <id1> <word1> <id2> ...\nå°†æ•°å­—è§†ä¸ºç”¨æˆ·IDï¼Œå…¶ä»–è§†ä¸ºå…³é”®è¯ã€‚")
            return

        try:
            config = load_config()
            # Ensure keys exist, initialize if not
            banned_ids = config['bot'].setdefault('banned_ids', [])
            banned_words = config['bot'].setdefault('banned_words', [])

            new_ids_added = []
            new_words_added = []
            already_banned_ids = []
            already_banned_words = []

            for token in tokens:
                try:
                    user_id = int(token)
                    if user_id not in banned_ids:
                        banned_ids.append(user_id)
                        new_ids_added.append(user_id)
                    else:
                        already_banned_ids.append(user_id)
                except ValueError:
                    # Treat as word
                    word = token
                    if word not in banned_words:
                        banned_words.append(word)
                        new_words_added.append(word)
                    else:
                        already_banned_words.append(word)

            # Only save if changes were made
            if new_ids_added or new_words_added:
                save_config(config)
                self.logger.info(f"Ban list updated. Added IDs: {new_ids_added}, Added Words: {new_words_added}")

            # Construct reply message
            reply_parts = []
            if new_ids_added:
                reply_parts.append(f"âœ… å·²æ·»åŠ é˜»æ­¢ ID: {', '.join(map(str, new_ids_added))}")
            if new_words_added:
                 reply_parts.append(f"âœ… å·²æ·»åŠ ç¦ç”¨è¯: {', '.join(new_words_added)}")
            if already_banned_ids:
                 reply_parts.append(f"â„¹ï¸ è¿™äº› ID å·²åœ¨é˜»æ­¢åå•ä¸­: {', '.join(map(str, already_banned_ids))}")
            if already_banned_words:
                 reply_parts.append(f"â„¹ï¸ è¿™äº›è¯å·²åœ¨ç¦ç”¨åå•ä¸­: {', '.join(already_banned_words)}")

            if not reply_parts: # Should not happen if tokens were provided but none were new
                 await event.reply("æä¾›çš„ ID/è¯è¯­å‡å·²åœ¨é˜»æ­¢/ç¦ç”¨åå•ä¸­ã€‚")
            else:
                 await event.reply("\n".join(reply_parts))

        except Exception as e:
            self.logger.error(f"å¤„ç† /ban å‘½ä»¤å‡ºé”™: {e}", exc_info=True)
            await event.reply(f"å¤„ç† /ban å‘½ä»¤æ—¶å‡ºé”™: {e}")


    @set_permission
    async def handle_banlist_command(self, event) -> None:
        """Handles the /banlist command."""
        try:
            config = load_config()
            banned_ids = config['bot'].get('banned_ids', [])
            banned_words = config['bot'].get('banned_words', [])

            # Format lists for display
            ids_str = "\n".join(f"- `{id}`" for id in banned_ids) if banned_ids else "æ— "
            words_str = "\n".join(f"- `{word}`" for word in banned_words) if banned_words else "æ— "

            reply_msg = (
                f"ğŸš« **å½“å‰é˜»æ­¢åå•ä¿¡æ¯**\n\n"
                f"**é˜»æ­¢çš„ç”¨æˆ· ID**:\n{ids_str}\n\n"
                f"**ç¦ç”¨çš„å…³é”®è¯**:\n{words_str}"
            )
            await event.reply(reply_msg, parse_mode='markdown')
        except Exception as e:
            self.logger.error(f"å¤„ç† /banlist å‘½ä»¤å‡ºé”™: {e}", exc_info=True)
            await event.reply(f"è·å–é˜»æ­¢åå•æ—¶å‡ºé”™: {e}")


    @set_permission
    async def handle_delete_command(self, event) -> None:
        """Handles the /delete command to remove documents containing keywords."""
        try:
            # Use provided keywords or default to BANNED_WORDS from config if empty
            tokens = event.text.split()[1:]
            target_keyword_list = tokens or BANNED_WORDS # Use configured BANNED_WORDS if no args given

            if not target_keyword_list:
                 await event.reply("ç”¨æ³•: /delete <å…³é”®è¯1> <å…³é”®è¯2> ...\næˆ–è€…ï¼Œå¦‚æœä¸æä¾›å…³é”®è¯ï¼Œå°†ä½¿ç”¨é…ç½®ä¸­çš„ `BANNED_WORDS`ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚å½“å‰æœªæä¾›å‚æ•°ä¸”é…ç½®ä¸­æ—  `BANNED_WORDS`ã€‚")
                 return

            # Sanitize keywords slightly before showing confirmation
            display_keywords = [f"`{kw}`" for kw in target_keyword_list] # Use backticks for clarity
            keywords_repr = repr(target_keyword_list) # Safe representation for callback data

            text = f"â“ ç¡®è®¤åˆ é™¤æ‰€æœ‰åŒ…å«ä»¥ä¸‹ä»»ä¸€å…³é”®è¯çš„æ–‡æ¡£ï¼Ÿ\n{', '.join(display_keywords)}"
            buttons = [
                Button.inline("æ˜¯ï¼Œåˆ é™¤", data=f"d`y`{keywords_repr}"), # Use repr for safe encoding
                Button.inline("å¦ï¼Œå–æ¶ˆ", data=f"d`n`")
            ]
            await event.reply(text, buttons=buttons, parse_mode='markdown')

        except Exception as e:
            self.logger.error(f"å‡†å¤‡ /delete å‘½ä»¤æ—¶å‡ºé”™: {e}", exc_info=True)
            await event.reply(f"å¤„ç† /delete å‘½ä»¤æ—¶å‡ºé”™: {e}")

    # --- Event Handlers ---

    async def handle_forwarded_message(self, event) -> None:
        """Handles forwarded messages to potentially ban the original sender."""
        if not event.is_private or not event.fwd_from or not event.fwd_from.from_id:
            return # Only handle private chats with valid forward info

        # Check if the sender is a user (not a channel)
        if not isinstance(event.fwd_from.from_id, PeerUser):
            # Optionally log or inform the user
            # self.logger.debug("Forwarded message is not from a user.")
            # await event.reply("âš ï¸ ä»…æ”¯æŒå¯¹æ¥è‡ªç”¨æˆ·çš„è½¬å‘æ¶ˆæ¯æ‰§è¡Œæ“ä½œã€‚")
            return

        try:
            from_user_id = event.fwd_from.from_id.user_id
            # Maybe get user info for display?
            # user = await self.bot_client.get_entity(from_user_id)
            # display_name = user.first_name + (f" {user.last_name}" if user.last_name else "")

            # Check if already banned before asking
            config = load_config()
            if from_user_id in config['bot'].get('banned_ids', []):
                 await event.reply(f"â„¹ï¸ ç”¨æˆ· `{from_user_id}` å·²åœ¨é˜»æ­¢åå•ä¸­ã€‚", parse_mode='markdown')
                 return

            text = f"â“ æ˜¯å¦å°†è½¬å‘æ¥æºç”¨æˆ· `{from_user_id}` æ·»åŠ åˆ°é˜»æ­¢åå•ï¼Ÿ"
            buttons = [
                Button.inline("æ˜¯", data=f"ban_yes_{from_user_id}"),
                Button.inline("å¦", data=f"ban_no_{from_user_id}")
            ]
            await event.reply(text, buttons=buttons, parse_mode='markdown')

        except AttributeError:
            # Should be caught by initial checks, but as safeguard
            self.logger.warning("æ— æ³•ä»è½¬å‘æ¶ˆæ¯ä¸­è·å– user_idã€‚")
            # await event.reply("âŒ æ— æ³•è·å–æ¥æºç”¨æˆ·ä¿¡æ¯ã€‚")
        except Exception as e:
             self.logger.error(f"å¤„ç†è½¬å‘æ¶ˆæ¯æ—¶å‡ºé”™: {e}", exc_info=True)
             # Avoid crashing, maybe just log


    # --- Callback Handlers ---

    async def handle_ban_callback(self, event, confirm: bool, user_id: int) -> None:
        """Handles the ban confirmation callback."""
        if not confirm:
            await event.edit("å·²å–æ¶ˆæ·»åŠ ã€‚")
            return

        try:
            config = load_config()
            banned_ids = config['bot'].setdefault('banned_ids', [])

            if user_id not in banned_ids:
                banned_ids.append(user_id)
                save_config(config)
                self.logger.info(f"ç”¨æˆ· {user_id} å·²é€šè¿‡å›è°ƒæ·»åŠ åˆ°é˜»æ­¢åå•ã€‚")
                await event.edit(f"âœ… ç”¨æˆ· `{user_id}` å·²æ·»åŠ åˆ°é˜»æ­¢åå•ã€‚", parse_mode='markdown')
            else:
                self.logger.info(f"ç”¨æˆ· {user_id} åœ¨å›è°ƒæ—¶å·²åœ¨é˜»æ­¢åå•ä¸­ã€‚")
                await event.edit(f"â„¹ï¸ ç”¨æˆ· `{user_id}` å·²åœ¨é˜»æ­¢åå•ä¸­ã€‚", parse_mode='markdown')
        except Exception as e:
            self.logger.error(f"å¤„ç† ban å›è°ƒå‡ºé”™ for user {user_id}: {e}", exc_info=True)
            await event.answer(f"æ·»åŠ é˜»æ­¢åå•å¤±è´¥: {e}", alert=True)


    async def handle_delete_callback(self, event, confirm: bool, keywords_repr: str) -> None:
        """Handles the delete confirmation callback."""
        if not confirm:
            await event.edit("å·²å–æ¶ˆåˆ é™¤ã€‚")
            return

        try:
            # Safely evaluate the keyword list representation
            delete_list = ast.literal_eval(keywords_repr)
            if not isinstance(delete_list, list):
                 raise ValueError("Invalid format for delete list in callback")

            self.logger.info(f"å¼€å§‹åˆ é™¤åŒ…å«å…³é”®è¯ {delete_list} çš„æ–‡æ¡£")
            await event.edit(f"â³ æ­£åœ¨åˆ é™¤åŒ…å«ä»¥ä¸‹å…³é”®è¯çš„æ–‡æ¡£ï¼š{', '.join(f'`{k}`' for k in delete_list)} ...", parse_mode='markdown')

            # Perform deletion (consider doing this in chunks or background task if large)
            # MeiliSearch delete is usually fast, but might block if deleting millions
            tasks = []
            total_deleted_count = 0 # Optional: track count

            # Note: Meilisearch `delete_documents_by_filter` might be more efficient
            # if you can construct a filter like `text CONTAINS 'word1' OR text CONTAINS 'word2'`
            # However, `delete_all_contain_keyword` seems to use search then delete IDs,
            # which might be okay. Let's stick to the original logic pattern.

            for keyword in delete_list:
                 # This method name is slightly misleading if it searches then deletes.
                 # It implies it deletes *all* documents *if* they contain the keyword.
                 # Let's assume it works as intended per the original code.
                 # A better Meili approach might use filters: client.index('telegram').delete_documents({'filter': f'text = "{keyword}"'})
                 # or more complex filters if needed.
                 # Sticking to the provided Meili Handler method:
                 try:
                     # We might want the handler method to return the number of deleted docs
                     # self.meili.delete_all_contain_keyword(f'"{keyword}"') # Ensure quotes if needed by method
                     self.meili.delete_all_contain_keyword(keyword) # Assuming method handles quoting if necessary
                     self.logger.info(f"å·²è§¦å‘åˆ é™¤åŒ…å« '{keyword}' çš„æ–‡æ¡£çš„ä»»åŠ¡ã€‚")
                     # Note: The original method doesn't seem async or return counts.
                     # If deletion takes time, this response might be premature.
                 except Exception as del_err:
                     self.logger.error(f"åˆ é™¤åŒ…å«å…³é”®è¯ '{keyword}' çš„æ–‡æ¡£æ—¶å‡ºé”™: {del_err}", exc_info=True)
                     await event.reply(f"âŒ åˆ é™¤å…³é”®è¯ `{keyword}` æ—¶å‡ºé”™: {del_err}") # Reply immediately on error

            # Consider waiting for tasks if the delete method was async and returned tasks
            # await asyncio.gather(*tasks)

            await event.edit(f"âœ… å·²å®Œæˆåˆ é™¤åŒ…å«æŒ‡å®šå…³é”®è¯çš„æ–‡æ¡£çš„ä»»åŠ¡ã€‚") # Edit confirmation

        except (SyntaxError, ValueError) as e:
             self.logger.error(f"è§£æåˆ é™¤å›è°ƒæ•°æ®å‡ºé”™: {keywords_repr} - {e}", exc_info=True)
             await event.answer("å¤„ç†åˆ é™¤è¯·æ±‚æ—¶å‡ºé”™ (æ•°æ®æ ¼å¼æ— æ•ˆ)ã€‚", alert=True)
        except Exception as e:
            self.logger.error(f"å¤„ç† delete å›è°ƒå‡ºé”™: {e}", exc_info=True)
            await event.answer(f"åˆ é™¤æ–‡æ¡£æ—¶å‘ç”Ÿé”™è¯¯: {e}", alert=True)

